{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Barrier Analysis Example\n",
    "\n",
    "This notebook demonstrates how to use the `BarrierAnalysis` module to evaluate signal quality using triple barrier outcomes (take-profit, stop-loss, timeout) instead of raw returns.\n",
    "\n",
    "**Key Features:**\n",
    "- Hit rate analysis by signal quantile\n",
    "- Profit factor analysis with monotonicity tests\n",
    "- Precision/recall curves for signal quality\n",
    "- Time-to-target analysis for trade timing\n",
    "- Interactive Plotly visualizations\n",
    "- HTML/JSON export\n",
    "\n",
    "**Reference:** Lopez de Prado (2018) \"Advances in Financial Machine Learning\" Chapter 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "from ml4t.diagnostic.config import BarrierAnalysisConfig\n",
    "\n",
    "# ML4T Diagnostic imports\n",
    "from ml4t.diagnostic.evaluation import BarrierAnalysis\n",
    "from ml4t.diagnostic.visualization import (\n",
    "    plot_hit_rate_heatmap,\n",
    "    plot_precision_recall_curve,\n",
    "    plot_profit_factor_bar,\n",
    "    plot_time_to_target_box,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Data\n",
    "\n",
    "We'll create synthetic data where:\n",
    "- Higher signal values predict take-profit (TP) outcomes\n",
    "- Lower signal values predict stop-loss (SL) outcomes\n",
    "\n",
    "This simulates a momentum-like signal with predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Generate dates and assets\n",
    "n_dates = 252  # ~1 year of trading days\n",
    "n_assets = 50\n",
    "start_date = date(2023, 1, 1)\n",
    "\n",
    "dates = [start_date + timedelta(days=i) for i in range(n_dates)]\n",
    "assets = [f\"ASSET_{i:03d}\" for i in range(n_assets)]\n",
    "\n",
    "print(f\"Dataset: {n_dates} dates x {n_assets} assets = {n_dates * n_assets:,} observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create signal data\n",
    "signal_rows = []\n",
    "for d in dates:\n",
    "    for asset in assets:\n",
    "        # Signal is a momentum-like score from -1 to 1\n",
    "        signal = np.random.uniform(-1, 1)\n",
    "        signal_rows.append({\"date\": d, \"asset\": asset, \"signal\": signal})\n",
    "\n",
    "signal_df = pl.DataFrame(signal_rows)\n",
    "print(\"Signal DataFrame:\")\n",
    "signal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create barrier labels correlated with signal\n",
    "barrier_rows = []\n",
    "\n",
    "for d in dates:\n",
    "    for asset in assets:\n",
    "        # Get same random signal (reproducible with same seed pattern)\n",
    "        signal = np.random.uniform(-1, 1)\n",
    "\n",
    "        # Higher signals -> higher TP probability\n",
    "        # Lower signals -> higher SL probability\n",
    "        p_tp = 0.25 + 0.35 * (signal + 1) / 2  # Range: 0.25 to 0.60\n",
    "        p_sl = 0.30 - 0.15 * (signal + 1) / 2  # Range: 0.30 to 0.15\n",
    "        p_timeout = 1 - p_tp - p_sl\n",
    "\n",
    "        # Sample outcome\n",
    "        outcome = np.random.choice([1, -1, 0], p=[p_tp, p_sl, p_timeout])\n",
    "\n",
    "        # Generate return based on outcome\n",
    "        if outcome == 1:  # Take-profit\n",
    "            ret = np.random.uniform(0.02, 0.05)  # 2-5% gain\n",
    "            bars = np.random.randint(3, 15)  # Faster exits for winners\n",
    "        elif outcome == -1:  # Stop-loss\n",
    "            ret = np.random.uniform(-0.03, -0.01)  # 1-3% loss\n",
    "            bars = np.random.randint(2, 10)  # Quick stops\n",
    "        else:  # Timeout\n",
    "            ret = np.random.uniform(-0.01, 0.01)  # Small return\n",
    "            bars = 20  # Hit max holding period\n",
    "\n",
    "        barrier_rows.append(\n",
    "            {\n",
    "                \"date\": d,\n",
    "                \"asset\": asset,\n",
    "                \"label\": outcome,\n",
    "                \"label_return\": ret,\n",
    "                \"label_bars\": bars,\n",
    "            }\n",
    "        )\n",
    "\n",
    "barrier_df = pl.DataFrame(barrier_rows)\n",
    "print(\"Barrier Labels DataFrame:\")\n",
    "barrier_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check outcome distribution\n",
    "print(\"\\nOutcome Distribution:\")\n",
    "outcome_counts = barrier_df.group_by(\"label\").agg(pl.count().alias(\"count\"))\n",
    "print(outcome_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create BarrierAnalysis\n",
    "\n",
    "Configure and instantiate the analysis with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure analysis\n",
    "config = BarrierAnalysisConfig(\n",
    "    n_quantiles=10,  # Use deciles (D1-D10)\n",
    "    signal_name=\"momentum\",  # Name for reports\n",
    "    significance_level=0.05,  # Alpha for statistical tests\n",
    ")\n",
    "\n",
    "# Create analysis instance\n",
    "analysis = BarrierAnalysis(signal_df, barrier_df, config=config)\n",
    "\n",
    "print(\"Analysis created:\")\n",
    "print(f\"  - Observations: {analysis.n_observations:,}\")\n",
    "print(f\"  - Assets: {analysis.n_assets}\")\n",
    "print(f\"  - Dates: {analysis.n_dates}\")\n",
    "print(f\"  - Date range: {analysis.date_range[0]} to {analysis.date_range[1]}\")\n",
    "print(f\"  - Quantile labels: {analysis.quantile_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hit Rate Analysis\n",
    "\n",
    "Analyze how hit rates (TP%, SL%, Timeout%) vary by signal quantile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute hit rates\n",
    "hit_rates = analysis.compute_hit_rates()\n",
    "\n",
    "print(\"Hit Rate Summary:\")\n",
    "print(f\"  - Chi-square statistic: {hit_rates.chi2_statistic:.2f}\")\n",
    "print(f\"  - P-value: {hit_rates.chi2_p_value:.6f}\")\n",
    "print(f\"  - Significant: {hit_rates.is_significant}\")\n",
    "print(f\"  - TP rate monotonic: {hit_rates.tp_rate_monotonic} ({hit_rates.tp_rate_direction})\")\n",
    "print(f\"  - Spearman correlation: {hit_rates.tp_rate_spearman:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View hit rates as DataFrame\n",
    "hit_rates.get_dataframe(\"hit_rates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize hit rate heatmap\n",
    "fig = plot_hit_rate_heatmap(hit_rates, show_counts=True, show_chi2=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Profit Factor Analysis\n",
    "\n",
    "Analyze profit factor (sum of TP returns / |sum of SL returns|) by quantile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute profit factor\n",
    "profit_factor = analysis.compute_profit_factor()\n",
    "\n",
    "print(\"Profit Factor Summary:\")\n",
    "print(f\"  - Overall PF: {profit_factor.overall_profit_factor:.2f}\")\n",
    "print(f\"  - PF monotonic: {profit_factor.pf_monotonic} ({profit_factor.pf_direction})\")\n",
    "print(f\"  - Spearman correlation: {profit_factor.pf_spearman:.3f}\")\n",
    "print(f\"  - Overall avg return: {profit_factor.overall_avg_return:.4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View profit factor by quantile\n",
    "profit_factor.get_dataframe(\"profit_factor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize profit factor bar chart\n",
    "fig = plot_profit_factor_bar(profit_factor, show_reference_line=True, show_average_return=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Precision/Recall Analysis\n",
    "\n",
    "Analyze precision and recall for identifying TP outcomes when trading top signal quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute precision/recall\n",
    "precision_recall = analysis.compute_precision_recall()\n",
    "\n",
    "print(\"Precision/Recall Summary:\")\n",
    "print(f\"  - Baseline TP rate: {precision_recall.baseline_tp_rate:.2%}\")\n",
    "print(f\"  - Total TP count: {precision_recall.total_tp_count:,}\")\n",
    "print(f\"  - Best F1 quantile: {precision_recall.best_f1_quantile}\")\n",
    "print(f\"  - Best F1 score: {precision_recall.best_f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View cumulative precision/recall\n",
    "precision_recall.get_dataframe(\"cumulative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize precision/recall curves\n",
    "fig = plot_precision_recall_curve(precision_recall, show_f1_peak=True, show_lift=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Time-to-Target Analysis\n",
    "\n",
    "Analyze how quickly trades exit (bars to exit) by quantile and outcome type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute time-to-target\n",
    "time_to_target = analysis.compute_time_to_target()\n",
    "\n",
    "print(\"Time-to-Target Summary:\")\n",
    "print(f\"  - Overall mean bars: {time_to_target.overall_mean_bars:.1f}\")\n",
    "print(f\"  - Overall median bars: {time_to_target.overall_median_bars:.1f}\")\n",
    "print(f\"  - TP mean bars: {time_to_target.overall_mean_bars_tp:.1f}\")\n",
    "print(f\"  - SL mean bars: {time_to_target.overall_mean_bars_sl:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View detailed time-to-target by quantile\n",
    "time_to_target.get_dataframe(\"detailed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize time-to-target (comparison mode: TP vs SL side by side)\n",
    "fig = plot_time_to_target_box(time_to_target, outcome_type=\"comparison\", show_median_line=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: view all outcomes\n",
    "fig = plot_time_to_target_box(time_to_target, outcome_type=\"all\", show_median_line=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Complete Tear Sheet\n",
    "\n",
    "Generate a comprehensive tear sheet with all analyses and export to HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create complete tear sheet with visualizations\n",
    "tear_sheet = analysis.create_tear_sheet(\n",
    "    include_figures=True,\n",
    "    include_time_to_target=True,\n",
    "    theme=\"default\",\n",
    ")\n",
    "\n",
    "print(\"Tear Sheet Summary:\")\n",
    "print(tear_sheet.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available DataFrames\n",
    "print(\"Available DataFrames:\")\n",
    "for name in tear_sheet.list_dataframes():\n",
    "    print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to HTML (uncomment to save)\n",
    "# tear_sheet.save_html(\"barrier_analysis_report.html\")\n",
    "# print(\"Report saved to barrier_analysis_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to JSON (uncomment to save)\n",
    "# tear_sheet.save_json(\"barrier_analysis_metrics.json\", exclude_figures=True)\n",
    "# print(\"Metrics saved to barrier_analysis_metrics.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Interpretation\n",
    "\n",
    "### What to Look For\n",
    "\n",
    "1. **Hit Rate Heatmap:**\n",
    "   - Green cells (high TP rate) should cluster in high quantiles (D8-D10)\n",
    "   - Red cells (high SL rate) should cluster in low quantiles (D1-D3)\n",
    "   - Significant chi-square test indicates signal predicts outcomes\n",
    "\n",
    "2. **Profit Factor Bar:**\n",
    "   - Bars above 1.0 (reference line) are profitable\n",
    "   - Increasing pattern from D1 to D10 indicates monotonicity\n",
    "   - Overall PF > 1.5 suggests a strong signal\n",
    "\n",
    "3. **Precision/Recall Curves:**\n",
    "   - Precision above baseline indicates above-random performance\n",
    "   - Best F1 quantile shows optimal trade selection threshold\n",
    "   - Lift > 1 means signal beats random selection\n",
    "\n",
    "4. **Time-to-Target:**\n",
    "   - TP trades exiting faster than SL is a good sign (\"winners run fast\")\n",
    "   - Top quantiles having faster TP exits validates signal quality\n",
    "   - Large spread in timing suggests regime-dependent behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Advanced: Theme Customization\n",
    "\n",
    "All visualizations support different themes for various use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dark theme (for dark mode presentations)\n",
    "fig = plot_hit_rate_heatmap(hit_rates, theme=\"dark\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print theme (for papers and reports)\n",
    "fig = plot_profit_factor_bar(profit_factor, theme=\"print\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presentation theme (larger fonts)\n",
    "fig = plot_precision_recall_curve(precision_recall, theme=\"presentation\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "The `BarrierAnalysis` module provides a comprehensive framework for evaluating signal quality using triple barrier outcomes. Key methods:\n",
    "\n",
    "| Method | Returns | Purpose |\n",
    "|--------|---------|--------|\n",
    "| `compute_hit_rates()` | `HitRateResult` | TP/SL/Timeout rates by quantile |\n",
    "| `compute_profit_factor()` | `ProfitFactorResult` | Profit factor by quantile |\n",
    "| `compute_precision_recall()` | `PrecisionRecallResult` | Precision/recall curves |\n",
    "| `compute_time_to_target()` | `TimeToTargetResult` | Bars to exit analysis |\n",
    "| `create_tear_sheet()` | `BarrierTearSheet` | Complete analysis + figures |\n",
    "\n",
    "For more details, see the [module documentation](../src/ml4t/diagnostic/evaluation/barrier_analysis.py)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
